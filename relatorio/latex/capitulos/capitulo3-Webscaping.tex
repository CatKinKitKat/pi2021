\chapter{Webscraping}
\label{cap3}

\section{Planeamento}
\subsection{Divisão de Tarefas}

A divisão de tarefas decidida foi a distribuição de cada um dos três \textit{websites} por cada um dos elementos do grupo, pela ordem de dificuldade em congruência linear com o tempo extra-curricular disponível de cada elemento.

\subsection{Tecnologias Usadas}
Na realização do \textit{webscraping} foi desenvolvido um ambiente virtual de \textit{Python 3} para realizar os \textit{scripts} que iriam recolher as informações.

Como forma de organizar todos os pacotes \href{https://github.com/CatKinKitKat/pi2021}{GitHub} e possíveis actualizações de bibliotecas dentro do código também foi gerado um ficheiro \textit{.txt} denominado \textit{requirements} que actualizávamos e usávamos sempre que um dos elementos do grupo iria realizar o seu trabalho.

A linguagem optada para a construção dos \textit{scripts} foi o \textit{Python} já que é uma das mais acessíveis linguagens de programação disponíveis devido à sua simples \textit{syntax} e também pela vasta quantidade de bibliotecas disponibilizadas, das quais temos uma dúzia que são bastante úteis para a realização deste projecto.

Para finalizar, todos os ficheiros foram guardados em formato \textit{.csv} uma vez que é um formato que é aceite e nos facilita a manipulação de dados (ETL), a alimentação dos dados ao algoritmo de \textit{machine learning}, e pode ser usado com ferramentas de análise e geradores de tabelas (como o PowerBI).

\subsubsection{Ambientes Virtuais de \textit{Python}}
Neste projecto usamos Ambientes Virtuais de \textit{Python}. Um ambiente virtual é uma forma de ter várias instâncias paralelas do interpretador de \textit{Python}, cada uma com diferentes conjuntos de pacotes e diferentes configurações.

Cada ambiente virtual contém uma cópia discreta do interpretador de \textit{Python}, incluindo cópias dos seus utilitários de suporte como o \href{https://pypi.org/project/pip/}{\textit{pip}}. Estes contêm também uma zona para instalação de pacotes/bibliotecas localmente (dentro do ambiente virtual), sendo esta a razão principal pela qual foi decidido usá-los.

Tendo introduzido a razão, consegue-se perceber o óbvio: sendo este um trabalho de grupo e que posteriormente poderá ser testado pelos docentes ou futuros alunos, ao usar ambientes virtuais podemos fazer \textit{pip freeze} para um ficheiro de texto do qual facilita a portabilidade e transmissão de requerimentos do projecto.

Para a criação destes ambientes virtuais foi instalado o \href{https://pypi.org/project/virtualenvwrapper/}{\textit{virtualenvwrapper}} o qual traz uma \textit{fork} com extensões úteis do \href{https://pypi.org/project/virtualenv/}{\textit{virtualenv}} como dependência e um \textit{set} de extensões para o mesmo.

\subsubsection{Bibliotecas de \textit{Python}}
Como dito previamente, na explicação pelo qual o uso de \textit{Python}, foi referida a grande quantidade de bibliotecas que nos são facilmente fornecidas pelo \href{https://pypi.org/project/pip/}{\textit{pip}}.

Dentro deste repositório existe (perto de) uma dúzia de bibliotecas que nos permitem facilmente completar as nossas tarefas deste projecto. Dessa dúzia, para esta etapa, foram usadas:
\begin{itemize}
  \setlength\itemsep{0.05em}
  \item \href{https://pypi.org/project/beautifulsoup4/}{\textit{BeautifulSoup4}}, uma biblioteca que facilita a extracção de informações de páginas da web, fornecendo expressões para iterar, pesquisar e modificar a árvore de análise;
  \item \href{https://pypi.org/project/lxml/}{\textit{lxml}}, uma biblioteca \textit{Python} que permite fácil manuseio de arquivos \textit{XML} e \textit{HTML};
  \item \href{https://pypi.org/project/requests/}{requests}, uma biblioteca \textit{HTTP} elegante e simples para \textit{Python}, construída de raiz para ser fácil de usar;
  \item \href{https://pypi.org/project/pandas/}{\textit{pandas}}, uma ferramenta de manipulação e análise de dados de código aberto rápida, poderosa, flexível e fácil de usar;
  \item \href{https://pypi.org/project/jupyter/}{\textit{jupyter}}, um meta-pacote o qual traz (como dependências) o sistema \textit{Jupyter} (em especial os cadernos), o \textit{kernel} \textit{IPython} e outros.
\end{itemize}

Com estes pacotes temos um mapa de actuação para esta etapa de projecto (de webscraping): abrir um ambiente virtual (e instalar bibliotecas), abrir um caderno de \textit{Jupyter}, importar as bibliotecas das quais usámos \textit{request} para ir buscar a nossa página, fazer \textit{parsing} da página via \textit{lxml}, criar um objecto \textit{Soup} com o conteúdo \textit{parsed}, fazer \textit{scraping} e iterar pelos \textit{scrapes} dos quais criámos \textit{dataframes} de \textit{pandas} e exportámos os mesmos em \textit{.csv} para uso futuro. Nas secções seguintes será explicado com mais detalhe de acordo com o \textit{website} em questão.

\section{Booking}   
\subsection{Estratégia}
Para a realização do \textit{webscraping} no \textit{website} da \href{www.Booking.com}{\textit{Booking.com}}, inicialmente foi necessário a filtragem pelos hotéis apenas na localidade de Beja \cite{yt1}, uma vez ser o local que o grupo em conjunto decidiu optar para realizar todas as pesquisas num sítio em comum.
Após ter o \textit{Booking} a apresentar todos os resultados para os hotéis de Beja, foi recolhido o link que redirecciona especificamente para esses resultados.
Para aceder ás informações específicas de cada elemento da página e mais tarde aceder aos mesmos para retirar a informação pretendida, foi usado a ferramenta de \textit{inspeccionar a página} e assim descobrir os nomes das classes e todos os outros elementos que continham conteúdo importante para o projecto \cite{yt1}, como o nome dos hotéis, preço, classificação, número de comentários e alguns outros detalhes que pudessem ser úteis.

Em seguida foi necessário realizar o \textit{webscraping} das \textit{reviews} de cada hotel, a realização desta parte foi um pouco mais difícil uma vez que para as \textit{reviews} serem bem recolhidas era fulcral que o \textit{webscraping} fosse realizado usando outro link \cite{yt1}, ou seja, foi retirado do \textit{website} o prefixo de um novo link que seria o \href{https://www.booking.com/reviews/pt/hotel/}{\textit{reviews}} e baseando nos hotéis já retirados foi colocado o nome de cada um à frente do mesmo. Criando assim um novo link que seria usado na realização do \textit{webscraping}. Após a criação de um novo link para cada hotel, os processos foram semelhantes aos anteriormente feitos.

Para finalizar, os resultados foram todos guardados em ficheiros \textit{.csv} para uma mais fácil visualização.

\subsection{Desenvolvimento}

Aqui detalha-se o processo de desenvolvimento do \textit{webscraping} do \textit{website} \href{https://www.booking.com/country/pt.pt-pt.html}{\textit{Booking}}.

\subsubsection{Hotéis}

Inicialmente foi feita a filtragem de apenas os hotéis de Beja.

No código foi implementado as bibliotecas \textit{BeautifulSoup4} para facilitar a tarefa de realizar o \textit{webscraping}. Esse mesmo código está disponível no repositório \href{https://github.com/CatKinKitKat/pi2021/tree/master/projecto/webscrape/scrapes}{GitHub} e no apêndice \hyperref[ap4]{4}.

A partir do \textit{website} ao inspeccionar a página era possível retirar os \textit{headers} que eram valores necessários na realização do \textit{webscraping}.
Também é realizado o pedido \textit{HTTP} e juntou-se a informação com a biblioteca \textit{BeautifulSoup4}.

Foram criados diferentes \textit{arrays} para receber as informações e posteriormente colocada a respectiva informação em cada um deles.

Devido a alguns \textit{arrays} conterem mais informação, possivelmente devido a algum tipo de informação adicional que possa estar em algum hotel especificamente, para prevenir erros, foram reduzidos ao tamanho do \textit{array} mais curto.

Por fim todos os resultados contidos nos \textit{arrays} foram guardados num ficheiro \textit{.csv} denominado \textit{listtable.csv}.

Construção dos links para realizar o \textit{webscraping} das \textit{reviews} de cada hotel.

Foi realizado o pedido \textit{HTTP} e juntado á biblioteca \textit{BeautifulSoup4} para aceder ás \textit{reviews} de cada site e todos os valores foram salvos no formato \textit{.csv}.

No final, temos esta tabela representativa dos hotéis \textit{scraped} ordenada e representativa dos \textit{scrapes} hotelXX\textit{.csv}.

\begin{table}[!ht]
  \centering
  \begin{tabular}{|l|l|l|l|}
    \hline
    ~  & Hotel                                              & Classificação & Preço \\ \hline
    0  & Hotel Bejense                                      & ``8,4''       & 189   \\ \hline
    1  & Aljana Guest House Beja                            & ``9,3''       & 330   \\ \hline
    2  & BejaParque Hotel                                   & ``8,1''       & 255   \\ \hline
    3  & Pousada Convento de Beja                           & ``8,7''       & 270   \\ \hline
    4  & Guest House Stories                                & ``8,7''       & 135   \\ \hline
    5  & Hotel Melius                                       & ``8,1''       & 242   \\ \hline
  \end{tabular}
  \caption{Tabela exemplar dos hotéis do \textit{Booking}}
  \label{table:2}
\end{table}

\subsection{Resultado}

Aqui exemplifica-se um ficheiro \textit{.csv}, hotel18\textit{.csv}, que contem os \textit{reviews} do hotel Quinta do Castelo.

\begin{table}[!ht]
  \centering
  \begin{adjustbox}{width=\columnwidth,center}
    \begin{tabular}{|l|l|}
      \hline
      ~     & Opiniões                                                                                                                                     \\ \hline
      0     & A localização é excelente assim como as condições do espaço. Local muito bem cuidado e apelativo. Fomos muito bem recebidos \dots            \\ \hline
      1     & Nada digno de registo.                                                                                                                       \\ \hline
      2     & A simpatia da Sra Catarina foi fantástica. A casa e as acomodações corresponderam ás expetivas e relação qualidade preço foi perfeita \ldots \\ \hline
      3     & Localização excelente, apartamento espaçoso, e totalmente equipado.
      O facto de ser uma construção antiga, cria um ambiente muito \ldots                                                                                  \\ \hline
      4     & A localização é impecável mesmo no centro histórico de Beja. Casa Limpa e organizada. Dona super prestável e e simpática.                    \\ \hline
      5     & De noite ouve-se o barulho da rua com muita facilidade.                                                                                      \\ \hline
    \end{tabular}
  \end{adjustbox}
  \caption{Tabela de resultados exemplar dos \textit{reviews} de um hotel do \textit{Booking}}
  \label{table:3}
\end{table}

\section{TripAdvisor}

O \href{https://www.tripadvisor.pt/}{TripAdvisor} é uma empresa americana de viagens \textit{online} que opera \textit{web} e \textit{mobile apps} com conteúdo \textit{user generated} e um website de comparação de preços, dos quais se pode fazer com hotéis, locais atractivos (como monumentos, parques, museus, etc..) e restauração.

Este como sendo um produto/serviço que oferece acesso a três categorias distintas (hotéis, restaurantes e atracções), foi divido em três partes que representam as três categorias.

Este \textit{website} é conhecido pelas suas tentativas de dificultar os processos de \textit{scraping} \cite{wws1}, o qual foi observado, mas resolvido a custo de tempo. Felizmente encontramos um \textit{website} chamado \href{https://www.worthwebscraping.com/}{\textit{Worth Web Scraping}} o qual nos mostrou como fazer na página de hotéis do \textit{TripAdvisor} o \textit{scraping} da tabela de referência e dos \textit{reviews} \cite{wws2}.

\subsection{Estratégia}

Após um \textit{scouting} inicial às páginas das três categorias, foi observado as seguintes peculiaridades:
\begin{itemize}
  \setlength\itemsep{0.05em}
  \item as páginas das três categorias são diferentes no seu \textit{layout} e organização;
  \item os nomes das classes nos \textit{span, div} e outros elementos são \textit{random generated} e mudam de acordo com a sessão aberta ou \textit{cookie};
  \item existem representações repetidas, estes são os \textit{posts sponsored} \cite{wws1} pelo próprio \textit{website};
  \item as subpáginas que nos retornam os \textit{reviews}, são de comprimentos diferentes de acordo com a categoria de \textit{listing} \cite{wws2};
  \item as subpáginas que nos retornam os \textit{reviews}, usam múltiplos de cinco ou dez na \textit{query};
  \item as subpáginas que nos retornam os \textit{reviews} mostram por defeito os que estão na linguagem referente ao dominio (.pt, .com, etc..) sem \textit{query parameter} para alterar,
  \item \textit{links} com \textit{query parameters} que representem uma subpágina não existente não dão erro 404 (Page not found), mas redireccionam para a primeira \cite{wws2};
  \item quando tentamos extrair o total de \textit{reviews} apenas conseguimos o total dos totais e não o total por linguagem, impedindo assim de fazer uma conta para saber qual o múltiplo de cinco ou dez que seria a ultima subpágina.
\end{itemize}

Assim sendo, a estratégia que foi usada, embora inapropriada em termos de tempo despendido e extracções redundantes, era a única que assegurava que se conseguia extrair todos os \textit{reviews}. Essa estratégia foi:
\begin{itemize}
  \setlength\itemsep{0.05em}
  \item criar uma lista de \textit{links} para 200 ou 400 subpáginas (de acordo com o \textit{listing} daquela categoria com mais \textit{reviews} em português);
  \item extrair incluindo os repetidos para um \textit{array/list/arraylist};
  \item usar compreensão de listas através de \textit{sets}/dicionários/\textit{tuples} que possam ser ordenados para remover repetidos e não perder ordem;
  \item transpor esses dados para um \textit{dataframe} de pandas e exportá-lo para \textit{.csv} para uso futuro.
\end{itemize}

\subsection{Desenvolvimento}

Aqui iremos detalhar o processo longo do \textit{webscraping} da plataforma \textit{TripAdvisor} e as suas três principais categorias.

\subsubsection{Atracções}
Para o desenvolvimento do \textit{webscraping} das Atracções de Beja, foi aberto um caderno de \textit{Jupyter} no qual começámos por fazer o \textit{import} das bibliotecas e desactivar o aviso da falta de certificado \textit{SSL} (após a introdução do trabalho em Inglês).

Seguidamente, foi feita a configuração do \textit{request} onde qual fazemos \textit{download} da página \textit{web} pretendida. Estes \textit{headers} foram extraídos do \textit{browser} do computador usado, \textit{Microsoft Edge (Chromium)}.

Após fazer \textit{request} e verificar o \textit{status code} (vazio ou 200 para OK), foi criado um objecto \textit{Soup} com o \textit{parsing (via lxml)} da página \textit{requested}.

Para a criação da tabela de referência das atracções fazemos um ciclo que nos vão fazer \textit{scrape} aos nomes.

Sendo que agora podemos simplesmente através destes \textit{arrays} criados fazer um \textit{dataframe} der \textit{pandas} via um dicionário de \textit{Python} com os variados \textit{pandas} referidos. Seguidamente exportamos o \textit{dataframe} para um ficheiro \textit{.csv}.

Agora um ciclo que retira os \textit{HTML tag} onde  contém um \textit{href} com uma parte do \textit{link} que nos possibilita (criar o \textit{link} inteiro e) visitar a pagina de \textit{reviews}.

Essas páginas têm determinadas restrições faladas nas secções anteriores e a sua solução. A qual aqui em baixo representada, cria uma enormidade de \textit{links} por local.
Dos quais \textit{links} agora serão \textit{scraped} (incluindo os \textit{reviews} repetidos e excepto os que contêm \textit{desde} e \textit{euros}) e seguidamente tratados (remoção de repetidos) indo seguidamente para um (dicionário e transformado num) \textit{dataframe} de \textit{pandas}, o qual é imediatamente exportado com o número do atracção referente na tabela de referência.
\subsubsection{Hotéis}

Para o desenvolvimento do \textit{webscraping} dos Hotéis de Beja, foi aberto um caderno de \textit{Jupyter} no qual começamos por fazer o \textit{import} das bibliotecas e desactivar o aviso da falta de certificado \textit{SSL} (após a introdução do trabalho em Inglês).

Seguidamente, foi feita a configuração do \textit{request} onde qual fazemos \textit{download} da página \textit{web} pretendida. Estes \textit{headers} foram extraídos do \textit{browser} do computador usado, \textit{Microsoft Edge (Chromium)}.

Após fazer \textit{request} e verificar o \textit{status code} (vazio ou 200 para OK), foi criado um objecto \textit{Soup} com o \textit{parsing (via lxml)} da página \textit{requested}.

Para a criação da tabela de referência dos hotéis fazemos um grupo de ciclos que nos vão fazer \textit{scrape} aos nomes, \textit{ratings}, número total de \textit{reviews} e preços. Sendo que este número de \textit{reviews} não nos vale de muito tal como previamente referido.

Sendo que agora podemos simplesmente através destes \textit{arrays} criados fazer um \textit{dataframe} der \textit{pandas} via um dicionário de \textit{Python} com os variados \textit{pandas} referidos. Seguidamente exportamos o \textit{dataframe} para um ficheiro \textit{.csv}.

O qual gerou uma tabela de hotéis como referência.

Mesmo que o número total de \textit{reviews} não nos seja relevante o \textit{HTML tag} onde é retirado contem um \textit{href} com uma parte do \textit{link} que nos possibilita (criar o \textit{link} inteiro e) visitar a pagina de \textit{reviews}.

Essas páginas têm determinadas restrições faladas nas secções anteriores e a sua solução. O que cria uma enormidade de \textit{links} por local.

Dos quais \textit{links} agora serão \textit{scraped} (incluindo os \textit{reviews} repetidos) e seguidamente tratados (remoção de repetidos) indo seguidamente para um (dicionário e transformado num) \textit{dataframe} de \textit{pandas}, o qual é imediatamente exportado com o número do hotel referente na tabela de referência.

\subsubsection{Restaurantes}
Para o desenvolvimento do \textit{webscraping} dos Restaurantes de Beja, foi aberto um caderno de \textit{Jupyter} no qual começamos por fazer o \textit{import} das bibliotecas e desactivar o aviso da falta de certificado \textit{SSL} (após a introdução do trabalho em Inglês).

Seguidamente, foi feita a configuração do \textit{request} onde qual fazemos \textit{download} da página \textit{web} pretendida. Estes \textit{headers} foram extraídos do \textit{browser} do computador usado, \textit{Microsoft Edge (Chromium)}.

Após fazer \textit{request} e verificar o \textit{status code} (vazio ou 200 para OK), foi criado um objecto \textit{Soup} com o \textit{parsing (via lxml)} da página \textit{requested}.

Para a criação da tabela de referência das atracções fazemos um ciclo que nos vão fazer \textit{scrape} aos nomes e as partes de \textit{href} contidas nos \textit{href} para a criação dos \textit{links} dos \textit{reviews}.

Sendo que agora podemos simplesmente através destes \textit{arrays} criados fazer um \textit{dataframe} der \textit{pandas} via um dicionário de \textit{Python} com os variados \textit{pandas} referidos. Seguidamente exportamos o \textit{dataframe} para um ficheiro \textit{.csv}. O qual gerou uma tabela de restaurantes como referência.

Agora um ciclo que vai buscar as partes de \textit{links} onde do ciclo anterior que nos possibilita (criar o \textit{link} inteiro e) visitar a página de \textit{reviews}.

Essas páginas têm determinadas restrições faladas nas secções anteriores e a sua solução. A qual aqui em baixo representada, cria uma enormidade de \textit{links} por local.

Dos quais \textit{links} agora serão \textit{scraped} (incluindo os \textit{reviews} repetidos) e seguidamente tratados (remoção de repetidos) indo seguidamente para um (dicionário e transformado num) \textit{dataframe} de \textit{pandas}, o qual é imediatamente exportado com o número do restaurante referente na tabela de referência.


\subsection{Resultado}
Aqui apresenta-se os resultados do \textit{webscrape} do \textit{TripAdvisor}. Os quais representam um exemplar dos dez primeiros \textit{reviews} do primeiro hotel, atracção e restaurante, respectivamente.

\begin{table}[!ht]
  \centering
  \begin{adjustbox}{width=\columnwidth,center}
    \begin{tabular}{|l|l|}
      \hline
      ~      & Avaliações                                                                                                               \\ \hline
      0      & Excelente hotel .  Pessoal da recepção e serviços de quarto muito atenciosos e prestativos -  o frigobar\ldots           \\ \hline
      1      & Património histórico ao seu melhor nível de recuperação, renovação e utilização. Magnificas salas,como\ldots             \\ \hline
      2      & Chegámos depois da meia-noite e fomos recebidos com extrema simpatia! Passámos o nosso aniversário de\ldots              \\ \hline
      3      & Gostei muito do alojamento e da estadia. Destaco a beleza, qualidade e localização da  pousada, a simpatia de\ldots      \\ \hline
      4      & Na reserva tinha a descrição de um tipo de quarto e foi atribuído outro. Parque infantil insuficiente e fechado.\ldots   \\ \hline
      5      & Boas instalações, uma óptima piscina, bons acessos e estacionamento.  Um inexcedível acolhimento, simpatia e\ldots       \\ \hline
    \end{tabular}
  \end{adjustbox}
  \caption{Tabela representativa dos cinco primeiros \textit{reviews} de um hotel do \textit{TripAdvisor}}
  \label{table:5}
\end{table}

\begin{table}[!ht]
  \centering
  \begin{adjustbox}{width=\columnwidth,center}
    \begin{tabular}{|l|l|}
      \hline
      ~      & Avaliações                                                                                                               \\ \hline
      0      & Muito bom.                                                                                                               \\ \hline
      1      & Castelo bem conservado, com torre de menagem altiva e exuberante, pena fechar a horas proibitivas. Pode-se dar a\ldots   \\ \hline
      3      & Castelo bonito numa zona central de Beja. Não se paga para entrar nem para andar pelas muralhas. A vista é bonita\ldots. \\ \hline
      4      & ~                                                                                                                        \\ \hline
      5      & No entanto, apesar de existirem pessoas dedicadas, não se vende qualquer tipo de recordações.                            \\ \hline
    \end{tabular}
  \end{adjustbox}
  \caption{Tabela representativa dos cinco primeiros \textit{reviews} de uma atracção do \textit{TripAdvisor}}
  \label{table:6}
\end{table}

\begin{table}[!ht]
  \centering
  \begin{adjustbox}{width=\columnwidth,center}
    \begin{tabular}{|l|l|}
      \hline
      ~      & Avaliações                                                                                                                  \\ \hline
      0      & Num bairro de Beja encontra-se este restaurante com esplanada e sala mediana. Carta com muitas sugestões de entradas\ldots  \\ \hline
      1      & Não se deixem intimidar pelo aspecto do restaurante. Comida ao nível de uma estrela Michelin. Bem confecionada\ldots        \\ \hline
      2      & duas pessoas, embora sendo individuais. Serviço simpático e pronto. O espaço não é condizente com a delícia da comida\ldots \\ \hline
      3      & Mais                                                                                                                        \\ \hline
      4      & Cozinhar divinamente, sem dúvida é uma arte! Nível de estrela Michelin e preço normal! Só retiraria a TV da sala\ldots      \\ \hline                                                                                                                     \\ \hline
    \end{tabular}
  \end{adjustbox}
  \caption{Tabela representativa dos cinco primeiros \textit{reviews} de um restaurante do \textit{TripAdvisor}}
  \label{table:6}
\end{table}

\section{\textit{Zomato}}
A \textit{Zomato} é um serviço de busca de restaurantes para quem quer sair para jantar, buscar comida ou pedir em casa. A \textit{Zomato} possui duas secções: guia de restaurante e \textit{blog}. Previamente, havia uma secção de eventos, já descontinuada.

O guia de restaurantes \textit{Zomato} permite ao usuário buscar informações relacionadas a restaurantes, bares, cafés, \textit{pubs} e casa nocturnas. As informações fornecidas geralmente incluem o nome do estabelecimento, telefones de contacto, endereço, cardápio, fotografias, avaliações e mapas de localização.

\subsection{Estratégia}
As páginas da \textit{web app} do \textit{Zomato} usam um \textit{paralax} de \textit{scrolling} infinito (até não haver mais restaurantes) e as classes dos \textit{HTML tags} mudam por sessão e/ou \textit{rendering}, logo aqui a estratégia é literalmente fazer \textit{download} da página \textit{web} e fazer o \textit{scrape} a partir do \textit{parsing} dessa página.

\subsection{Desenvolvimento}
Aqui é representada uma aproximação do desenvolvimento deste \textit{scraping}.
\subsubsection{Restaurantes}
Primeiramente foi feito o \textit{import} das bibliotecas.

Depois pegando no código dos colegas como \textit{template}, adaptou-se para usar uma página previamente descarregada.

Fazemos um ciclo de \textit{scraping} dos nomes dos locais de consumo.

E agora dois ciclos, um para as classes com nome gerado no \textit{prerender} e outra pós \textit{render}; vamos buscar os tipos/classes de restaurantes, e outros dois ciclos do mesmo motivo, para ir buscar os preços. Pelo mesmo motivo criámos dois ciclos; que vão buscar os \textit{links} das páginas dos \textit{reviews}, o qual extraímos todos os \textit{tags} de parágrafos porque que sempre que se corria o código gerava uma classe nova.

\subsection{Resultado}
Os resultados deste \textit{scrape} foram desapontantes no mínimo devido à infeliz \textit{random generated} nome da classe, que é gerado por cada vez que se usa a página. Estes resultados vão sofrer muito \textit{ETL} posterior.