\chapter{Pré-processamento}
\label{cap4}

Esta etapa consiste em remover todos os caracteres especiais, que não são letras, números ou espaços \cite{u1}. As quais podemos considerar diacrítico como caracteres especiais ou não. Dependendo do caso, podemos remover todos os caracteres especiais, ou apenas os que não são diacríticos \cite{cr1}.

Nos nossos casos de análise textual, houve necessidade de remover todos os caracteres especiais, mas os diacríticos podem ser úteis para a nossa análise, em especial nos passos seguintes, extracção de \textit{keywords} e análise de \textit{sentiments}, foram descartados ou usados respectivamente, pelo motivo da precisão da análise em questão.

\section{Metodologia}

Para remover os caracteres especiais, foram criados dois \textit{scripts}, um para limpar os ficheiros \textit{.csv} e outro tratar do texto em si, que consiste em remover os caracteres especiais, fazer a normalização dos caracteres via \textit{NFKD} e aplicar a remoção de acentos \cite{cr1}, caso seja necessário (apenas alterando o último passo de \textit{encoding}/\textit{decoding}).

Estes não requerem bibliotecas externas, podem ser executados em \textit{Python 3}, e as suas bibliotecas \textit{standard}.

\subsection{Limpar ficheiros}

O \textit{script trimer.py} é responsável fazer \textit{trimming} (remover espaços em branco), remover linhas em branco e colocar aspas duplas em cada \textit{review}. Para estes foi necessário o uso de expressões regulares \cite{u1}.

\subsection{Limpar texto dos \textit{reviews}}

O \textit{script normalize} é responsável por remover caracteres especiais, fazer a normalização dos caracteres via \textit{NFKD} e aplicar a remoção de acentos \cite{cr1}, caso seja necessário (apenas alterando o último passo de \textit{encoding}/\textit{decoding}).

\section{Execução}

Executamos o \textit{script trimer.py} para limpar os ficheiros \textit{.csv} \cite{gfg1} e o \textit{script} \textit{normalize} para limpar o texto dos \textit{reviews}. Estes aceitam um caminho para uma pasta com os ficheiros \textit{.csv} e itera sobre os ficheiros, executando as funções de limpeza.

Após a execução da limpeza textual e normalização sem remoção de acentos, seguidamente realizámos com remoção de acentos para que tenhamos ambas as versões. Para a versão com remoção de acentos, foi necessário usar o pacote \textit{Unidecode} para aplicar a remoção de acentos \cite{cr1}.

Com estas duas versões podemos obter os resultados óptimos para a nossa análise textual.

\section{Resultados}

Os ficheiros \textit{.csv} foram limpos e normalizados sem remoção de acentos e com remoção de acentos.