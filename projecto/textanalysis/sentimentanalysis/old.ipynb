{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sentiment Analysis\n","\n","In this notebook, we will use a dataset of movie reviews to train a model to predict whether a review is positive or negative. We will use the [ultc-movies.csv](https://www.kaggle.com/fredericods/ptbr-sentiment-analysis-datasets?select=utlc_movies.csv) to train the model (this is not o the Github repo due to it's size).\n","\n","To train the model, we will use the [`sklearn.feature_extraction.text.CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to create a bag of words representation of the reviews with a [`nltk.stem.SnowballStemmer`](https://www.nltk.org/api/nltk.stem.html#nltk.stem.SnowballStemmer) to stem the words, and [`sklearn.naive_bayes.MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) as our machine learning model.\n","\n","We will use the [`sklearn.metrics.classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to evaluate the model."]},{"cell_type":"markdown","metadata":{},"source":["## Importing the libraries\n","\n","Here we import the libraries we will use."]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["import os\n","import re\n","import warnings\n","import unicodedata\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import SnowballStemmer"]},{"cell_type":"markdown","metadata":{},"source":["## Creating a custom tokenizer\n","\n","We'll need a custom tokenizer that stems the words in our reviews. We will use the [`nltk.stem.SnowballStemmer`](https://www.nltk.org/api/nltk.stem.html#nltk.stem.SnowballStemmer) to stem the words.\n","\n","This tokenizer will be used to create a bag of words representation of the reviews. "]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["class StemmerTokenizer:\n","    def __init__(self):\n","        self.stemmer = SnowballStemmer(\"portuguese\")\n","    def __call__(self, doc):\n","        return [self.stemmer.stem(t) for t in word_tokenize(doc)]"]},{"cell_type":"markdown","metadata":{},"source":["## Functions\n","\n","Now we will define the functions we will use. We will use the following functions:\n","+ **create_dataframe**: to create a dataframe from the csv file\n","+ **load_directory**: to load the data from the directory\n","+ **get_training_data**: to get the training data\n","+ **drop_useless_columns**: to drop the columns that we don't need\n","+ **get_csv**: to get the csv file\n","+ **filter_string**: to filter the string\n","+ **integer**: to convert the string to an integer\n","+ **get_count_vectorizer_with_stopwords**: to get the count vectorizer with stopwords\n","+ **normalize**: to normalize the data\n","+ **emotion_from_int**: to get the emotion from the integer\n","+ **predict**: to predict the emotion"]},{"cell_type":"markdown","metadata":{},"source":["### Function: create_dataframe\n","\n","This function will create a dataframe from the csv file."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def create_dataframe(filename):\n","    nan_value = float(\"NaN\")\n","    df = pd.read_csv(filename)\n","    df.replace(\"\", nan_value, inplace=True)\n","    df.dropna(how=\"any\", inplace=True)\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["### Function: load_directory\n","\n","This function will load the data from the directory."]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["def load_directory(directory):\n","    files = []\n","    for filename in os.listdir(directory):\n","        if filename.endswith(\".csv\") and not filename.startswith(\"list\"):\n","            files.append(filename)\n","    return files"]},{"cell_type":"markdown","metadata":{},"source":["### Function: get_training_data\n","\n","This function will get the training data."]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["def get_training_data():\n","    df = create_dataframe(\n","        \"models/utlc_movies.csv\"\n","    )  # original_index,review_text,review_text_processed,review_text_tokenized,polarity,rating,kfold_polarity,kfold_rating\n","    df = drop_useless_columns(df)\n","    df = df.rename(columns={\"polarity\": \"Class\", \"review_text_processed\": \"Data\"})\n","    df = df.reindex(columns=[\"Class\", \"Data\"])\n","    return df.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Function: drop_useless_columns\n","\n","This function will drop the columns that we don't need."]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["def drop_useless_columns(df):\n","    df.drop(\n","        [\n","            \"original_index\",\n","            \"review_text\",\n","            \"review_text_tokenized\",\n","            \"rating\",\n","            \"kfold_polarity\",\n","            \"kfold_rating\",\n","        ],\n","        axis=1,\n","        inplace=True,\n","    )\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["### Function: get_csv\n","\n","This function will get the csv file."]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["def get_csv(path):\n","    df = create_dataframe(path)\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["### Function: filter_string\n","\n","This function will filter the string."]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["def filter_string(df, column):\n","    ret = (\n","        df[column]\n","        .apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n","        .apply(lambda x: re.sub(\" +\", \" \", x))\n","        .apply(lambda x: x.strip())\n","        .apply(lambda x: x.lower())\n","        .apply(lambda x: normalize(x))\n","        .values\n","    )\n","    return ret"]},{"cell_type":"markdown","metadata":{},"source":["### Function: integer\n","\n","This function will convert the string to an integer."]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["def integer(x):\n","    return int(x)"]},{"cell_type":"markdown","metadata":{},"source":["### Function: get_count_vectorizer_with_stopwords\n","\n","This function will get the count vectorizer with stopwords."]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def get_count_vectorizer_with_stopwords():\n","    return CountVectorizer(\n","        tokenizer=StemmerTokenizer(),\n","        ngram_range=(1, 2),\n","        stop_words=stopwords.words(\"portuguese\"),\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### Function: normalize\n","\n","This function will normalize the data."]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["def normalize(text):\n","    text = (\n","        unicodedata.normalize(\"NFKD\", text)\n","        .encode(\"ascii\", \"ignore\")\n","        .decode(\"utf-8\", \"ignore\")\n","    )\n","    return text"]},{"cell_type":"markdown","metadata":{},"source":["### Function: emotion_from_int\n","\n","This function will get the emotion from the integer."]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["def emotion_from_int(x):\n","    if x == 0:\n","        return \"Negative\"\n","    elif x == 1:\n","        return \"Positive\"\n","    else:\n","        return \"Unknown\""]},{"cell_type":"markdown","metadata":{},"source":["### Function: predict\n","\n","This function will predict the emotion."]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["def predict(model, vec, directory):\n","    files = load_directory(directory)\n","    for filename in files:\n","        df_predict = get_csv(directory + \"/\" + filename)\n","        predict_data = filter_string(df_predict, \"Avaliacoes\")\n","        # print(\"Loaded data to predict\")\n","        reviews = []\n","        sentiments = []\n","        for review in predict_data:\n","            sentiment = emotion_from_int(\n","                model.predict(vec.transform([review]).toarray())[0]\n","            )\n","            # print(\"Model predicts that: \" + str(review) + \" is \" + str(sentiment))\n","            reviews.append(str(review))\n","            sentiments.append(str(sentiment))\n","        with open(\n","            directory.replace(\"scrapes\", \"sentimentanalysis\") + \"/\" + filename,\n","            \"w\",\n","            encoding=\"utf-8\",\n","        ) as f:\n","            f.write(\"Sentiment, Review\\n\")\n","            for i in range(len(reviews)):\n","                f.write('\"' + sentiments[i] + '\", \"' + reviews[i] + '\"\\n')"]},{"cell_type":"markdown","metadata":{},"source":["## Execution\n","\n","Now we will execute the code."]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded training data\n","Loaded test data\n","Created vectorizer\n","Transformed training data\n","Transformed test data\n","Created model\n","Trained model\n","Tested model: 87.98% accuracy\n"]}],"source":["warnings.filterwarnings(\"ignore\")\n","\n","df = get_training_data()\n","df_test = df.sample(frac=0.1, random_state=42).reset_index(drop=True)\n","\n","df = df[:15000]\n","df_test = df_test[:5000]\n","\n","train_data, train_class = (\n","    filter_string(df, \"Data\"),\n","    df[\"Class\"].apply(lambda x: integer(x)).values,\n",")\n","print(\"Loaded training data\")\n","\n","test_data, test_class = (\n","    filter_string(df_test, \"Data\"),\n","    df_test[\"Class\"].apply(lambda x: integer(x)).values,\n",")\n","print(\"Loaded test data\")\n","\n","vec = get_count_vectorizer_with_stopwords()\n","print(\"Created vectorizer\")\n","\n","train_data = vec.fit_transform(train_data).toarray()\n","print(\"Transformed training data\")\n","\n","test_data = vec.transform(test_data).toarray()\n","print(\"Transformed test data\")\n","\n","model = MultinomialNB()\n","print(\"Created model\")\n","\n","model.fit(train_data, train_class)\n","print(\"Trained model\")\n","\n","print(\n","    \"Tested model: \" + str(model.score(test_data, test_class) * 100) + \"%\" + \" accuracy\"\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["Prediction of the emotion of the reviews of various establishments of various types and platforms and export the results to a csv file."]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["predict(model, vec, \"../scrapes/booking/hotels\")\n","predict(model, vec, \"../scrapes/zomato/restaurantes\")\n","predict(model, vec, \"../scrapes/tripadvisor/hotels\")\n","predict(model, vec, \"../scrapes/tripadvisor/restaurants\")\n","predict(model, vec, \"../scrapes/tripadvisor/activities\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":2}
